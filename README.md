# DissaMM: Explainable Multi-Modal AI for Disaster Response

DissaMM is a lightweight, explainable, multi-modal neural architecture for classifying disaster-related social media posts. It uses a modified ResNet-50 for image feature extraction and BERT for textual encoding, with their outputs fused through a compact MLP head. This design enables real-time, interpretable disaster monitoring to support humanitarian operations, while keeping computational cost low.

![DissaMM Architecture](images/2disaster.png)

<p align="center">
  <img src="images/2disaster.png" alt="DissaMM Architecture" width="70%">
  <br>
  <em>Figure: Architecture of the DissaMM model</em>
</p>
